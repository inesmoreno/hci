<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Low-fidelity prototype and Test Plan</title>
    <link
      rel="stylesheet"
      href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css"
      integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z"
      crossorigin="anonymous"
    />
    <link rel="stylesheet" href="styles.css" />
  </head>
  <body>
    <header>
      <div class="logo"><a href="/">üë©‚Äçüíª</a></div>
      <nav>
        <ul class="nav__links">
          <li><a href="observation.html">Observation and Proposal</a></li>
          <li>
              <a href="lowfi.html">Low-Fi Prototype</a>
          </li>
          <!-- <li><a href="#">low-fidelity Prototypes</a></li> -->
          <!-- <li><a href="#">##</a></li> -->
        </ul>
      </nav>
    </header>
    <section>
      <div class="container">
        <h1 class="text-center">
          Low-Fidelity Prototype and test plan
        </h1>
        <br />
        <h2 class="text-center">1. Design Concepts</h2>
        <br>
        <p>
          Based on our observations, we noted that participants of presentations can‚Äôt express the same non-verbal cues as in in-person presentations. For instance, often in video presentations, raised hands go unnoticed. In general, participants struggle to express information that would otherwise be expressed through body language or facial expression. This limits the way presenters and participants can engage with each other and especially dampens dialogue. Most software for video conferencing does not have many features to encourage other forms of communication and participation in presentation, and those that do have these features buried behind menus and drop downs.

        </p>
        <p>Our goal is to create a system that will help participants and presenters interact more casually during video-conferencing. By providing the ability for participants to ‚Äúemote‚Äù during presentations, then aggregate and display this information to everyone, we hope to increase participation. This feature will support more non-disruptive forms of communication for participants and provide presenters with easy to interpret statistics of participant reactions.
        </p>
        <br>
        <h4  class="text-center" >10 plus 10 session</h4>
        <br>
        <p>Here are the ideas that were generated in our first 10 plus 10 brainstorming session. First, we didn‚Äôt constrain the technology feasibility and the layout of our possible designs, rather we explored all possible design options. </p>
        <img src="images/sketch0.jpg" class="img-fluid" alt="Mental model 1" />
        <br />
        <br />
        <img src="images/sketch1.jpg" class="img-fluid" alt="Mental model 1" />
        <br />
        <br />
        <img src="images/sketch2.jpg" class="img-fluid" alt="Mental model 2" />
        <br />
        <br />
        <p>
          After this session, we settled on a single column interface which doesn‚Äôt incorporate video conferencing tools. We wanted our system to be used by anyone, no matter their choice of video-conferencing platform. From that, we generated many ideas about the style and format of the interface, namely where key features like raising hand or emoting would go. Here are the ideas we came up with:
        </p>
        <img src="images/sketch3.jpg" class="img-fluid" alt="Mental model 1" />
        <br />
        <br />
        <img src="images/sketch4.jpg" class="img-fluid" alt="Mental model 2" />
        <br />
        <br />

        <br />
        <br />
        <br />

        <section class="prototypes">
          <h2 class="text-center">2. Prototypes</h2>
          <p>
            <br />
            We bounced our ideas off each other with sketches and conducted
            usability testing with our paper prototypes. For the usability
            testing, we ran the wizard of Oz testing as below:
          </p>
          <img
          src="images/wizard.gif"
          class="img-fluid"
        />

        <br>
        <br>
        <h4 class="text-center">The Prototypes</h4>
        <br />
        Here are the three initial prototypes we landed on. The only changes at this point was the layout of the features and panels in our program.
      </p>
      <br>
      <h4 class="text-center">Prototype A</h4>
      <img
      src="images/pro-a.png"
      class="img-fluid"
      width="60%"
    />
    <br>
      <h4 class="text-center">Prototype B</h4>
      <img
      src="images/pro-b.png"
      class="img-fluid"
      width="60%"
    />
    <br>
      <h4 class="text-center">Prototype C</h4>
      <img
      src="images/pro-c.png"
      class="img-fluid"
      width="60%"
    />
    <br>
    <br>
          <br />
          <div class="design">
            <h4 class="text-center">Design decisions</h4>
            Having worked on our sketches and prototypes, we made several design
            decisions.
            <br />
            <br>
            <ul>
              <li>
               <u>  Not to incorporate videoconferencing in our website. </u>
                <ul>
                  <li>
                    In order to make our system accessible to everyone, we decided not to integrate it into any existing video-conferencing platform. Rather, we opted to create a stand-alone web app that can be opened in a separate window and positioned next to the video conferencing software. That way, our system can be used by anyone, no matter their choice of video-conferencing platform. This will also help us in terms of feasibility as we will not have to deal with complicated code bases and integrating our features with existing platforms like Zoom.
                  </li>
                </ul>
              </li>
            </ul>
            <ul>
              <li>
               <u>Vertical display </u>
                <ul>
                  <li>
                    We chose a vertical display as it is easy to organize our
                    features from top to bottom while sharing the screen real
                    estate with a video conferencing software. This also
                    facilitates displaying on tablets or phones if users decide
                    to use those instead of having two different windows open.
                  </li>
                </ul>
              </li>
            </ul>
            <ul>
              <li>
               <u>Integrate chat feature </u>
                <ul>
                  <li>
                    At first, we were debating whether we should create a chat
                    feature in our app, or rely on the user video conferencing
                    platform‚Äôs chat feature. We ultimately decided to add a chat
                    feature to our application. Having chat functionality in our
                    app means that users don‚Äôt need to continually go back to
                    the video conferencing software they use. Having a chat
                    feature rounds out our application and provides more of a
                    ‚Äúone stop‚Äù app that meets more use cases.
                  </li>
                </ul>
              </li>
            </ul>
            <ul>
              <li>
               <u> Toggle display for aggregate emoji reacts </u>
                <ul>
                  <li>
                    We were unsure if we should show aggregated emoji responses
                    as a raw number beside the respective emoji, or as a bar
                    graph histogram of emoji responses. Instead of choosing
                    between these two views, we decided to give users the option
                    to toggle between both views (number score and bar graph).
                    This way users can adjust the display of the app in a way
                    that works best for them.
                  </li>
                </ul>
              </li>
            </ul>
            <ul>
              <li>
               <u>  Express participant level of understanding on a 2D line +
                visualize it in a distribution </u>

                <ul>
                  <li>
                    When it comes to the ‚Äúlevel of understanding‚Äù feature that
                    aggregates how participants self report their understanding
                    of the presentation content, we chose to have users input
                    their level of understanding as a point on a spectrum and
                    display the class aggregate as a distribution. For
                    participants, articulating their understanding on a spectrum
                    opposed to discrete emoji allows for more precise expression
                    on the part of the participant. Displaying the aggregated
                    level of understanding, we opted for a distribution as this
                    will make it easier for the presenter to draw conclusions
                    from the data, as he will be able to see in real-time how
                    the ‚Äòlevel of understanding‚Äô trend for the audience moves
                    when they make further explanations or present new topics.
                  </li>
                </ul>
              </li>
            </ul>
            <ul>
              <li>
              <u> Display participant position in questions queue </u>
                <ul>
                  <li>
                    Regarding the ‚Äúhand raising‚Äù queue populated by participants
                    raising their hand, we chose to not show participants the
                    names of the other participants in the queue. Instead, we
                    decided to simply display the number of participants with
                    their hand up, and if the participant raised their hand,
                    what position they are in the queue. We did this to
                    declutter the UI. We thought the position in the queue would
                    be helpful as students can anticipate when they will be
                    called on to ask their question to the presenter and provide
                    a fair (first come, first serve) order to questions.
                  </li>
                </ul>
              </li>
            </ul>
            <ul>
              <li>
               <u> Polling with emoji </u>
                <ul>
                  <li>
                    Most polling features in video conferencing software opens a
                    new popup window. We decided to have an integrated poll
                    feature embedded directly in the interface. We chose this
                    because our observation findings showed us pop up windows
                    can be distracting and annoying to users.
                  </li>
                  <li>
                    We also decided to reuse the ‚Äúreactions‚Äù panel that displays
                    popular participant reactions to display polling answers.
                    This means students vote with an emoji (ex üÖ∞, üÖ±) and class
                    aggregates are displayed in the reactions panel. This is
                    better than a dedicated polling panel for two reasons: it
                    saves space, and allows participants to express ‚ÄúI don‚Äôt
                    know‚Äù or ‚Äúthinking‚Äù emojis while answering. These latter
                    emoji reactions are particularly valuable to a presenter.
                  </li>
                </ul>
              </li>
            </ul>
            <br>
            <h4 class="text-center">Working flow for participants</h4>
            <br>
            <br>
            <h5 class="text-center">Express "‚ÄúI don‚Äôt understand‚Äù</h4>
            <br>
            <img
              src="images/workingflow1.jpg"
              class="img-fluid"
              alt="Mental model 1"
            />
            <br />
            <br />
            <br>
            <h5 class="text-center">Participants want to speak</h4>
            <br>
            <img
              src="images/workingflow2.jpg"
              class="img-fluid"
              alt="Mental model 2"
            />
            <br />
            <br />
            <br>
            <h5 class="text-center">Emote reactions
            </h4>
            <br>
            <img
              src="images/workingflow3.jpg"
              class="img-fluid"
              alt="Mental model 1"
            />
            <br />
            <br />
            <br>
            <h5 class="text-center">See other participant‚Äôs reactions and answer poll questions
            </h4>
            <br>
            <img
              src="images/workingflow4.jpg"
              class="img-fluid"
              alt="Mental model 2"
            />
            <br />
            <br />
            <br>
            <h5 class="text-center">See the participant list
            </h4>
            <br>
            <img
              src="images/workingflow5.jpg"
              class="img-fluid"
              alt="Mental model 1"
            />
            <br />
            <br />
            <h4  class="text-center" >Working flow for Presenters</h4>
            <br>
            <h5 class="text-center">Ask multiple-choice question to participants and view polling results</h4>
            <br>
            <img
              src="images/workingflow6.jpg"
              class="img-fluid"
              alt="Mental model 2"
            />
            <br />
            <br />
            <br>
            <h5 class="text-center">Notice the rasied hands and lower them</h4>
            <br>
            <img
              src="images/workingflow7.jpg"
              class="img-fluid"
              alt="Mental model 1"
            />
            <br />
            <br />

            <br>
            <h5 class="text-center">Check to see if participants are following along</h4>
            <br>
            <img
              src="images/workingflow8.jpg"
              class="img-fluid"
              alt="Mental model 2"
            />
            <br />
            <br />
            <br />
          </div>
          <br />
          <br />
        </section>


          <div class="usablegoals">
          <h2 class="text-center">3. Usability goals & benchmark tasks</h2>
          <br>
          <h4>Usability Goals</h4>

           <ul>
            <li> <u> Learnability: </u> the system should be easily learned by new users

              <ul>
                <li>
                  Rationale: We want our system to be accessible to anyone using videoconferencing softwares, so users should be able to understand the functionalities offered within minutes of using it.         </li>
              </ul>
            </li>

            <li><u>Ease of use:</u>  the system should be easy to interact with 
            
                <ul>
                  <li>
                    Rationale: One of the main drawbacks of current video-conferencing tools like Zoom is that they provide an extensive range of features (raising hands, emoji reactions, polling, chat) but they are buried behind different menus and are hard to visualize at the same time (need of switching between windows/layouts‚Ä¶). We aim to offer a system where all interactions can be made in real time and without the need of switching to different windows/apps.           </li>
                </ul>
              </li>
              <li> <u>Efficiency:</u> Software is not distracting and supports live emotional expression
               <br> <i>Users should be able to react in real-time and view trends with minimal disruptions to focus.</i>
                  <ul>
                    <li>
                      Rationale: Our system is aimed to be used during presentations so it must not be overly disruptive or distracting to the presenter and/or participants. It should also provide support for students to express their emotional state in real-time with a variety of features without disrupting the presentation. If features are hard to access, users waste their time and can lose focus on the presentation.       </li>

                  </ul>
                </li>

                   <li> <u>Effectiveness:</u> Software increases engagement 
                    <br> <i>The user should feel more comfortable to express themselves and feel more a part of the presentation.</i>
                       <ul>
                         <li>
                          Rationale: Users can emote and see the class aggregate emotes while remaining anonymous. This will help students (especially shy or anxious students) a less stressful way to engage in the class. This kind of emotional investment helps support participant engagement and overall investment in the presentation.    </ul>
                     </li>
                     <li> <u>Satisfaction: </u> Users should be satisfied when using the system. 
                      
                         <ul>
                           <li>
                            Rationale: The goal of this project is to improve existing video-conferencing. Users should be satisfied with the system and feel it as a valuable add-on to the existing video-conferencing tools.

                         </ul>
                       </li>
                <br>
               <i> Please note that the last usability goals will be assessed in the post-test questionnaire. </i>

           </ul>
           <br>
          <h4>The benchmark tasks</h4>
          <br>
          <h5 class="text-center">Tasks for the participant</h5>
          <table>
            <tr id="ROW3">
              <th>Task </th>
              <th>Related Usability goals</th>
            </tr>
            <tr>
              <td>Let the presenter know you‚Äôre following</td>
              <td>1,2,3,4</td>
            </tr>
            <tr>
              <td>Send a message in the chat</td>
              <td>1,2,4</td>
            </tr>
            <tr>
              <td>Add yourself to the question queue </td>
              <td>1,2,3,4</td>
            </tr>
            <tr>
              <td>Remove yourself from the question queue </td>
              <td>1,2,3</td>
            </tr>
            <tr>
              <td>Answer to polling question</td>
              <td>1,2,3,4</td>
            </tr>
            <tr>
              <td>View polling results on bar chart </td>
              <td>1,2,3</td>
            </tr>
            <tr>
              <td>Check which students are connected </td>
              <td>1,2</td>
            </tr>
            <tr>
              <td>Give the presenter a love-reaction  </td>
              <td>1,2,3,4</td>
            </tr>
          </table>
          <br>
          <br>
          <h5 class="text-center">Tasks for the presenter</h5>
          <table>
            <tr id="ROW3">
              <th>Task </th>
              <th>Related Usability goals</th>
            </tr>
            <tr>
              <td>Assess how students are following along</td>
              <td>1,2,3,4</td>
            </tr>
            <tr>
              <td>Check which reaction has the highest count</td>
              <td>1,2,3,4</td>
            </tr>
            <tr>
              <td>Look up who is next in the question queue and delete them from the queue </td>
              <td>1,2,3</td>
            </tr>
            <tr>
              <td>See multiple choice answers </td>
              <td>1,2,3</td>
            </tr>
            
          </table>
        </div>
        <br>
        <br>
        <div>
          <h2 class="text-center">4. Test Materials</h2>
        <ul>
          <li>
            <a href="images/Observer briefing.pdf" download>Observer briefing</a>
        </li>
        <li>
            <a href="images/User Introduction.pdf" download>User Introduction</a>
        </li>
        <li>
            <a href="images/Pre-test-presenter.pdf" download>Preset questionnaire for Presenters</a>
        </li>
        <li>
            <a href="images/Pre-test-presenter.pdf" download>Preset questionnaire for Participants</a>
        </li>
        <li>
            <a href="images/participant-documentation.pdf" download>User training documentation for participants</a> 
        </li>
        <li>
          <a href="images/presenter-documentation.pdf" download>User training documentation for presenters</a> 
      </li>
        <li>
            <a href="images/Task Descriptions.pdf" download>Task descriptions</a> 
        </li>
        <li>
            <a href="images/Test script.pdf" download>Test Script</a>
        </li>
        <li>
            <a href="images/DataCollectionSheet.pdf" download>Data collection sheet</a>
        </li>
        <li>
            <a href="images/Post-test-q-pre.pdf" download> Post-test questionnaire for Presenters</a>
        </li>
        <li>
            <a href="images/Post-test-q-part.pdf" download> Post-test questionnaire for Participants</a>
        </li>
      </ul>
        </div>
        <br />
        <br />
        <br />

        <div>
          <h2 class="text-center">5. Summary of Test</h2>
          <br />
          <p>As planned, we conducted the wizard of Oz testing with our paper prototypes. These are clips from our recorded sessions:</p>
         <div class="text-center">
          <video width="320" height="240" controls>
            <source src="images/participant.mp4" type="video/mp4">
         
          Your browser does not support the video tag.
          </video>
        <br />
        <br />
        <video width="320" height="240" controls>
          <source src="images/presenter.mp4" type="video/mp4">
      
        Your browser does not support the video tag.
        </video>
      </div> 
      <br />
      <br>
        <h4>Subject A (Participant) </h4>
      <br>
      <a href="images/subjectAconsent.jpg" download>The ethics consent form</a> <br>
      <br>
      <p>Subject A is a student at HEC. She works at Desjardins and uses video conferencing daily for her work and school. She feels comfortable using video conferencing tools and participates in her online class during lectures when asked to.</p>
      
      <table>
        <tr id="ROW3">
          <th>Task </th>
          <th>Reached?</th>
          <th>Time taken</th>
          <th>Observations</th>
        </tr>
        <tr id="ROW1">
          <td>Let presenter know you‚Äôre following</td>
          <td>N</td>
          <td>2 secs</td>
          <td><u>Participant used an unintended feature</u> <br>
            First the participant tried to type the message in a chat box. And then they clicked one of the emojis. The participant  did not use the ‚Äúemotion bar‚Äù here.</td>
        </tr>
        <tr>
          <td>Send a message on the chat</td>
          <td>Y</td>
          <td>2 secs</td>
          <td>.</td>
        </tr>
        <tr>
          <td>Add yourself in the question queue</td>
          <td>Y</td>
          <td>2 secs</td>
          <td>.</td>
        </tr>
        <tr>
          <td>Remove yourself from the question queue</td>
          <td>Y</td>
          <td>2 secs</td>
          <td>.</td>
        </tr>
        <tr>
          <td>Answer the poll</td>
          <td>Y</td>
          <td>2 secs</td>
          <td>.</td>
        </tr>
        <tr>
          <td>View the polling result</td>
          <td>Y</td>
          <td>2 secs</td>
          <td> <u>The participant knew where to check this right away. </u>
            <br>
            However, when asked to check the bar graph version of the results: user paused to think about it (~5sec). She first tried to emote, unsuccessfully, then she noticed the toggle button and clicked on it. When she figured out what that button was doing, it took her 2 secs to switch back and forth between views. She had learned the feature.
            </td>
        </tr>
        <tr id="ROW1">
          <td >Check who are connected</td>
          <td>N</td>
          <td>10 secs</td>
          <td><u>User got confused, took a long time to reach task </u>
            <br>
            The user spent time looking for the feature. Incorrectly tried to emote first, then tried the chat. The participant seems confused. Finally clicked the ‚Äúpeople‚Äù button after ten seconds.  </td>
        </tr>
        <tr>
          <td>Emote love emoji</td>
          <td>Y</td>
          <td>2 secs</td>
          <td> .</td>
                   </tr>
      </table>
      <br>
      
      <br>
      <h4>Subject B (Presenter) </h4>
    <br>
    <a href="images/subjectBconsent.pdf" download>The ethics consent form</a> <br>

    <br>
    <p>The subject B is a developer. He uses the video conferencing software 4 to 6 times a week for work. He delivers a presentation during the code reviews, daily meetings and bug fixing sessions. He is very comfortable using videoconferencing tools. Participants of his presentations engage during the talk only when they have a question. His participants use webcam, voice chat and text chat, but do not raise their hand and or use emotes (ex. ‚Äúyes‚Äù ‚Äúno‚Äù ‚Äúclap‚Äù etc. in Zoom)
   
      <br>
      <table>
          <tr id="ROW3">
            <th>Task </th>
            <th>Reached?</th>
            <th>Time taken</th>
            <th>Observations</th>
          </tr>
          <tr id="ROW1">
            <td>Assess how students are following along upon looking at the student understanding graph</td>
            <td>N</td>
            <td>10 secs</td>
            <td><u>Graph was initially hard to interpret</u> <br>
              When the graph was flat, the subject was confused and didn‚Äôt seem to know how to interpret it. He intendedly clicked on the emoji to gain more context. Once the graph changed however, he understood how to interpret the graph.    </tr>
          <tr>
            <td>Checks the emote with the highest count</td>
            <td>Y</td>
            <td>5 secs</td>
            <td>.</td>
          </tr>
          <tr>
            <td>Sees who the next participant is in the question queue</td>
            <td>Y</td>
            <td>2 secs</td>
            <td>.</td>
          </tr>
          <tr>
            <td>Remove yourself from the question queue</td>
            <td>Y</td>
            <td>2 secs</td>
            <td>.</td>
          </tr>
          <tr id="ROW1">
            <td>Deletes person who just asked a question</td>
            <td>N</td>
            <td>Never done</td>
            <td>We forgot the button in our prototype</td>
          </tr>
          <tr>
            <td>Ask a multiple choice question and check the answer with the highest count</td>
            <td>Y</td>
            <td>2 secs</td>
            <td>.</td>
             </td>
          </tr>
          <tr id="ROW1">
            <td >Check people who is connected</td>
            <td>N</td>
            <td>2 secs</td>
            <td><u>Participant used an unintended feature </u>
              <br>
              User knew that he had to look at the chat but did not click on the ‚ÄòPeople‚Äô button. He suggested that he would send a message on the chat and wait for responses in order to accomplish this task     </tr>
        </table>
        <br>
        <h5>The post test Interview</h5>
        <p>Subject B stated that they would like to see the number of people expressing ‚Äúthe level of understanding‚Äù. They like the bar graph of emoji results with numbers displayed. The subject B likes that the distribution of the level of understanding is real-time as they can always check if participants are following their presentation. Overall, it is good that all results are anonymous. The subject believes that this software is especially useful for introverted participants. </p>
        <br>
        <br>
        <h4>Future improvements</h4>
        <p>A few improvements became clear to us upon the data analysis:</p>  
        <b>Clearer labelling on level of understanding</b>
        <p>Both the participant and presenter had issues initially using and interpreting the level of understanding graph. This is understandable, given the lack of titles, subtitles, and labelling around the graph. To mitigate confusing, we hope to include a title, x and y axis labels, and other text around the graph.</p>
        <br>
      </div>
    </section>
  </body>
</html>
