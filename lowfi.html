<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Low-fidelity prototype and Test Plan</title>
    <link
      rel="stylesheet"
      href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css"
      integrity="sha384-JcKb8q3iqJ61gNV9KGb8thSsNjpSL0n8PARn9HuZOnIxN0hoP+VmmDGMN5t9UJ0Z"
      crossorigin="anonymous"
    />
    <link rel="stylesheet" href="styles.css" />
  </head>
  <body>
    <header>
      <div class="logo"><a href="/">üë©‚Äçüíª</a></div>
      <nav>
        <ul class="nav__links">
          <li><a href="../observation.html">Observation and Proposal</a></li>
          <li>
              <a href="../lowfi.html">Low-Fi Prototype</a>
          </li>
          <!-- <li><a href="#">low-fidelity Prototypes</a></li> -->
          <!-- <li><a href="#">##</a></li> -->
        </ul>
      </nav>
    </header>
    <section>
      <div class="container">
        <h1 class="text-center">
          Low-Fidelity Prototype and test plan
        </h1>
        <br />
        <h2 class="text-center">1. Design Concepts</h2>
        <br>
        <p>
          Based on our observations, we noted that participants of presentations can‚Äôt express the same non-verbal cues as in in-person presentations. For instance, often in video presentations, raised hands go unnoticed. In general, participants struggle to express information that would otherwise be expressed through body language or facial expression. This limits the way presenters and participants can engage with each other and especially dampens dialogue. Most software for video conferencing does not have many features to encourage other forms of communication and participation in presentation, and those that do have these features buried behind menus and drop downs.

        </p>
        <p>Our goal is to create a system that will help participants and presenters interact more casually during video-conferencing. By providing the ability for participants to ‚Äúemote‚Äù during presentations, then aggregate and display this information to everyone, we hope to increase participation. This feature will support more non-disruptive forms of communication for participants and provide presenters with easy to interpret statistics of participant reactions.
        </p>
        <br>
        <h4  class="text-center" >10 plus 10 session</h4>
        <p>Here are the ideas that were generated in our first 10 plus 10 brainstorming session. First, we didn‚Äôt constrain the technology feasibility and the layout of our possible designs, rather we explored all possible design options. </p>
        <img src="images/sketch0.jpg" class="img-fluid" alt="Mental model 1" />
        <br />
        <br />
        <img src="images/sketch1.jpg" class="img-fluid" alt="Mental model 1" />
        <br />
        <br />
        <img src="images/sketch2.jpg" class="img-fluid" alt="Mental model 2" />
        <br />
        <br />
        <p>
          After this session, we settled on a single column interface which doesn‚Äôt incorporate video conferencing tools. We wanted our system to be used by anyone, no matter their choice of video-conferencing platform. From that, we generated many ideas about the style and format of the interface, namely where key features like raising hand or emoting would go. Here are the ideas we came up with:
        </p>
        <img src="images/sketch3.jpg" class="img-fluid" alt="Mental model 1" />
        <br />
        <br />
        <img src="images/sketch4.jpg" class="img-fluid" alt="Mental model 2" />
        <br />
        <br />

        <br />
        <br />
        <br />

        <section class="prototypes">
          <h2 class="text-center">2. Prototypes</h2>
          <p>
            <br />
            We bounced our ideas off each other with sketches and conducted
            usability testing with our paper prototypes. For the usability
            testing, we ran the wizard of Oz testing as below:
          </p>
          <img
          src="images/wizard.gif"
          class="img-fluid"
        />

        <br>
        <br>
          
          <br />
          <div class="design">
            <h4 class="text-center">Design decisions</h4>
            Having worked on our sketches and prototypes, we made several design
            decisions.
            <br />
            <br>
            <ul>
              <li>
               <u>  Not to incorporate videoconferencing in our website. </u>
                <ul>
                  <li>
                    In order to make our system accessible to everyone, we decided not to integrate it into any existing video-conferencing platform. Rather, we opted to create a stand-alone web app that can be opened in a separate window and positioned next to the video conferencing software. That way, our system can be used by anyone, no matter their choice of video-conferencing platform. This will also help us in terms of feasibility as we will not have to deal with complicated code bases and integrating our features with existing platforms like Zoom. 
                  </li>
                </ul>
              </li>
            </ul>
            <ul>
              <li>
               <u>Vertical display </u> 
                <ul>
                  <li>
                    We chose a vertical display as it is easy to organize our
                    features from top to bottom while sharing the screen real
                    estate with a video conferencing software. This also
                    facilitates displaying on tablets or phones if users decide
                    to use those instead of having two different windows open.
                  </li>
                </ul>
              </li>
            </ul>
            <ul>
              <li>
               <u>Integrate chat feature </u> 
                <ul>
                  <li>
                    At first, we were debating whether we should create a chat
                    feature in our app, or rely on the user video conferencing
                    platform‚Äôs chat feature. We ultimately decided to add a chat
                    feature to our application. Having chat functionality in our
                    app means that users don‚Äôt need to continually go back to
                    the video conferencing software they use. Having a chat
                    feature rounds out our application and provides more of a
                    ‚Äúone stop‚Äù app that meets more use cases.
                  </li>
                </ul>
              </li>
            </ul>
            <ul>
              <li>
               <u> Toggle display for aggregate emoji reacts </u>
                <ul>
                  <li>
                    We were unsure if we should show aggregated emoji responses
                    as a raw number beside the respective emoji, or as a bar
                    graph histogram of emoji responses. Instead of choosing
                    between these two views, we decided to give users the option
                    to toggle between both views (number score and bar graph).
                    This way users can adjust the display of the app in a way
                    that works best for them.
                  </li>
                </ul>
              </li>
            </ul>
            <ul>
              <li>
               <u>  Express participant level of understanding on a 2D line +
                visualize it in a distribution </u>

                <ul>
                  <li>
                    When it comes to the ‚Äúlevel of understanding‚Äù feature that
                    aggregates how participants self report their understanding
                    of the presentation content, we chose to have users input
                    their level of understanding as a point on a spectrum and
                    display the class aggregate as a distribution. For
                    participants, articulating their understanding on a spectrum
                    opposed to discrete emoji allows for more precise expression
                    on the part of the participant. Displaying the aggregated
                    level of understanding, we opted for a distribution as this
                    will make it easier for the presenter to draw conclusions
                    from the data, as he will be able to see in real-time how
                    the ‚Äòlevel of understanding‚Äô trend for the audience moves
                    when they make further explanations or present new topics.
                  </li>
                </ul>
              </li>
            </ul>
            <ul>
              <li>
              <u> Display participant position in questions queue </u> 
                <ul>
                  <li>
                    Regarding the ‚Äúhand raising‚Äù queue populated by participants
                    raising their hand, we chose to not show participants the
                    names of the other participants in the queue. Instead, we
                    decided to simply display the number of participants with
                    their hand up, and if the participant raised their hand,
                    what position they are in the queue. We did this to
                    declutter the UI. We thought the position in the queue would
                    be helpful as students can anticipate when they will be
                    called on to ask their question to the presenter and provide
                    a fair (first come, first serve) order to questions.
                  </li>
                </ul>
              </li>
            </ul>
            <ul>
              <li>
               <u> Polling with emoji </u> 
                <ul>
                  <li>
                    Most polling features in video conferencing software opens a
                    new popup window. We decided to have an integrated poll
                    feature embedded directly in the interface. We chose this
                    because our observation findings showed us pop up windows
                    can be distracting and annoying to users.
                  </li>
                  <li>
                    We also decided to reuse the ‚Äúreactions‚Äù panel that displays
                    popular participant reactions to display polling answers.
                    This means students vote with an emoji (ex üÖ∞, üÖ±) and class
                    aggregates are displayed in the reactions panel. This is
                    better than a dedicated polling panel for two reasons: it
                    saves space, and allows participants to express ‚ÄúI don‚Äôt
                    know‚Äù or ‚Äúthinking‚Äù emojis while answering. These latter
                    emoji reactions are particularly valuable to a presenter.
                  </li>
                </ul>
              </li>
            </ul>
            <br>
            <h4 class="text-center">Working flow for participants</h4>
            <br>
            <br>
            <h5 class="text-center">Express "‚ÄúI don‚Äôt understand‚Äù</h4>
            <br>
            <img
              src="images/workingflow1.jpg"
              class="img-fluid"
              alt="Mental model 1"
            />
            <br />
            <br />
            <br>
            <h5 class="text-center">Participants want to speak</h4>
            <br>
            <img
              src="images/workingflow2.jpg"
              class="img-fluid"
              alt="Mental model 2"
            />
            <br />
            <br />
            <br>
            <h5 class="text-center">Emote reactions
            </h4>
            <br>
            <img
              src="images/workingflow3.jpg"
              class="img-fluid"
              alt="Mental model 1"
            />
            <br />
            <br />
            <br>
            <h5 class="text-center">See other participant‚Äôs reactions and answer poll questions
            </h4>
            <br>
            <img
              src="images/workingflow4.jpg"
              class="img-fluid"
              alt="Mental model 2"
            />
            <br />
            <br />
            <br>
            <h5 class="text-center">See the participant list
            </h4>
            <br>
            <img
              src="images/workingflow5.jpg"
              class="img-fluid"
              alt="Mental model 1"
            />
            <br />
            <br />
            <h4  class="text-center" >Working flow for Presenters</h4>
            <br>
            <h5 class="text-center">Ask multiple-choice question to participants and view polling results</h4>
            <br>
            <img
              src="images/workingflow6.jpg"
              class="img-fluid"
              alt="Mental model 2"
            />
            <br />
            <br />
            <br>
            <h5 class="text-center">Notice the rasied hands and lower them</h4>
            <br>
            <img
              src="images/workingflow7.jpg"
              class="img-fluid"
              alt="Mental model 1"
            />
            <br />
            <br />
            
            <br>
            <h5 class="text-center">Check to see if participants are following along</h4>
            <br>
            <img
              src="images/workingflow8.jpg"
              class="img-fluid"
              alt="Mental model 2"
            />
            <br />
            <br />
            <br />            
          </div>
          <br />
          <br />
        </section>

        
          <div class="usablegoals">
          <h2 class="text-center">3. Usability goals & benchmark tasks</h2>
          <br>
          <h4>Usability Goals</h4>
             
           <ul>
            <li> <u> Ease of use and  learning </u>
              <ul>
                <li>
                  Rationale: One of the main drawbacks of current video-conferencing tools like Zoom is that they provide an extensive range of features (raising hands, emoji reactions, polling, chat) but they are hard to visualize at the same time (need of switching between windows/layouts‚Ä¶). We aim to offer a system where all interactions can be made in real time and without the need of switching to different windows/apps. We also want our system to be accessible to anyone using videoconferencing softwares, so users should be able to understand the functionalities offered within minutes of using it.  
<li> Benchmark task: open the webapp, and describe all the functionalities you can identify at first glance. 
</li>
                </li>
              </ul>
            </li>
            <li><u>Effectiveness and efficiency  </u>  - Users should be able to react in real-time and view trends without being distracted

                <ul>
                  <li>
                    Rationale: Our system is aimed to be used during presentations so it must not be overly disruptive or distract the presenter and/or participants from  following the presentation. It should also work in real-time to approximate the feeling of giving a presentation in-person.
<li> Benchmark tasks:  Ask presenter to tell how many participants are feeling lost at a point in time (measure how long they take in telling us this), Ask  if participants get distracted when others input reactions (see the count go up/down, see the trend curve move)
</li>
                  </li>
                </ul>
              </li>
              <li> <u> Utility/Engagement </u> - Users should feel that the system enables them to achieve their goals.

                  <ul>
                    <li>
                      Rationale: Users should find our system pleasant to use and appropriate for their presentations. They should feel like it is a clear add-on to the existing video-conferencing tools.
                    </li>
                    <li>
                      Benchmark: Ask users to rate their experience with the tool, if they will incorporate this in their practice (for presenters) or would like to have it (for participants)

                    </li>
                  </ul>
                </li>
             
           </ul>
           <br>
          <h4>The benchmark tasks</h4>
           <ul>
             <li>
              <u>  Tasks for the participant </u>
               <ul>
                 <li>
                   Expresses whether they are understanding the material or not using the scale 
                  </li>
                  <li>Emotes the mood they are feeling at the time 
                    </li>
                    <li>Sends a message in the chat
                      </li>
                      <li>Adds themselves to the ‚Äúquestions‚Äù queue
                        </li>   
                        <li>Responds to a multiple choice question with emoji
                          </li>   
 
               </ul>
             </li>
             <li>
               <u>Tasks for the presenter </u>
               <ul>
                 <li>
                    Checks the students level of understanding
                 </li>
                 <li>
                    Checks the emote with the highest count
                 </li>
                 <li>
                    Sees who the next participant is in the question queue
                 </li>
                 <li>
                    Sends a message in the chat
                 </li>
                 <li>
                    Ask a question to the participants, sees their answers in emotes
                 </li>
               </ul>
             </li>
           </ul>
           
        </div>    
        <br>
        <br>
        <div>
          <h2 class="text-center">4. Test Materials</h2>
        <ul>
          <li>
            <a href="#" download>Observer briefing</a> 
        </li>
        <li>
            <a href="images/User Introduction.pdf" download>User Introduction</a> 
        </li>
        <li>
            <a href="images/Pre-test-presenter.pdf" download>Preset questionnaire for Presenters</a> 
        </li>
        <li>
            <a href="images/Pre-test-presenter.pdf" download>Preset questionnaire for Participants</a> 
        </li>
        <li>
            <a href="images/participant-documentation.pdf" download>User training documentation</a> 
        </li>
        <li>
            <a href="images/Task Descriptions.pdf" download>Task descriptions</a> 
        </li>
        <li>
            <a href="#" download>Test Script</a> 
        </li>
        <li>
            <a href="images/DataCollectionSheet.pdf" download>Data collection sheet</a> 
        </li>
        <li>
            <a href="#" download> Post-test questionnaire for Presenters</a> 
        </li>
        <li>
            <a href="#" download> Post-test questionnaire for Participants</a> 
        </li>
      </ul>
        </div>
        <br />
        <br />
        <br />

        <div>
          <h2 class="text-center">5. Summary of Test</h2>
          <br />
         
        <br />
      </div>
    </section>
  </body>
</html>
